---
layout: default
description: Sara Beery
---

<div id="posts">
  
  <img src="assets/sara_field_work.jpeg">
  
  <h1>About</h1>

  <p>I am a PhD Candidate at Caltech, advised by <a href="http://www.vision.caltech.edu/Perona.html">Pietro Perona</a> and funded by an <a href="https://www.nsfgrfp.org/">NSF Graduate Research Fellowship</a> and a PIMCO Fellow in Data Science. I completed two bachelors degrees (BS in Electrical Engineering, BS in Math) at Seattle University where I was advised by <a href="https://www.seattleu.edu/scieng/about/faculty-and-staff/agnieszka-miguel-phd.html">Agnieszka Miguel</a>. My research focuses on machine learning and computer vision for biodiversity monitoring, particularly for detection and recognition of animal species in challenging camera trap data at a global scale. I work closely with <a href="https://github.com/Microsoft/CameraTraps">Microsoft AI for Earth</a> and <a href="https://ai.google/about/">Google Research</a>/<a href="https://wildlifeinsights.org/home-0">Wildlife Insights</a> where I help turn my research into usable tools for the ecology/biodiversity community.</p>

  <p>I believe STEM should be accessible to all, regardless of gender, race, age, nationality, sexuality, or religion, and I am passionate about increasing diversity and inclusion in STEM through mentorship and outreach.</p>
  
  <p>I'm an ex-professional ballerina who now spends her free time traveling and tasting wine, ask me for recommendations for all three! You can reach me at sbeery [at] caltech [dot] edu</p>

  
  <h1>Datasets & Models</h1>
  <ul>
    <li><a href="https://beerys.github.io/CaltechCameraTraps/">Caltech Camera Traps Dataset</a></li>
    <li><a href="https://github.com/microsoft/CameraTraps/blob/master/megadetector.md">Microsoft AI for Earth MegaDetector</a></li>
    <li><a href="https://github.com/tensorflow/models/blob/master/research/object_detection/README.md#june-17th-2020">Context R-CNN</a></li>
  </ul>
  <h1>Competitions</h1>
  <ul>
    <li><a href="https://www.kaggle.com/c/iwildcam-2020-fgvc7">iWildCam 2020</a></li>
    <li><a href="https://www.kaggle.com/c/iwildcam-2019-fgvc6">iWildCam 2019</a></li>
    <li><a href="https://www.kaggle.com/c/iwildcam2018">iWildCam 2018</a></li>
  </ul>
  <h1>Media</h1>
  <ul>
    <li><a href="https://ai.googleblog.com/2020/06/leveraging-temporal-context-for-object.html">Leveraging Temporal Context for Object Detection: Google AI Blog</a></li>
    <li><a href="https://www.youtube.com/watch?v=5q0amc-i1Jk">How do I get started using machine learning for my camera traps?: WILDLABS Tech Tutorial</a></li>
    <li><a href="https://cacm.acm.org/news/243929-cnns-catch-animals-in-the-wild/fulltext">CNNS Catch Animals in the Wild: Article in ACM News</a></li>
    <li><a href="https://www.youtube.com/watch?v=ddEZzCl7Lg4&feature=youtu.be">CompSust Open Graduate Seminar</a></li>
    <li><a href="https://www.microsoft.com/en-us/research/blog/internships-ahoy-with-kirsten-bray-wei-dai-and-sara-beery/">Microsoft Research Podcast</a></li>
    <li><a href="https://breakthrough.caltech.edu/magazine/2018-nov/#article-The-Big-Picture">Caltech Breakthrough Campaign</a></li>
    <li><a href="https://www.youtube.com/watch?v=7B_sf7mnpkc">WILDLABS Virtual Meetup: Camera Trapping</a></li>
    <li><a href="https://www.youtube.com/watch?v=aBmM5PNVD8Q&t=1h22m2s">Camera Trap Technology Symposium</a></li>
    <li><a href="https://www.seattleu.edu/newsroom/stories/technology-for-biodiversity.html">Technology for Biodiversity - The Seattle University Newsroom</a></li>
    <li><a href="https://dancemagazine.com.au/2017/06/sleep-performance-and-weight-management/">Dance Magazine</a></li>
    <li><a href="https://www.seattleu.edu/newsroom/stories/dancer-engineer-mathematician.html">Dancer, Engineer, Mathematician - The Seattle University Newsroom</a></li>
  </ul>
</div>
