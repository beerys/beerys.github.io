<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Sara Beery</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<section id="header">
				<header>
					<span class="image avatar"><img src="images/sara2crop.jpeg" alt="" /></span>
					<h1 id="logo"><a href="#">Sara Beery</a></h1>
					<p>Computer Vision for the Environment,<br />
						Sustainability, and Conservation</p>
				</header>
				<nav id="nav">
					<ul>
						<li><a href="#about" class="active">About</a></li>
						<li><a href="#research_group">Research Group</a></li>
 						<li><a href="#talks">Talks</a></li>
						<li><a href="#publications">Publications</a></li>
<!-- 						<li><a href="#media">Media</a></li> -->
						<li><a href="#datasets">Datasets & Models</a></li>
						<li><a href="#teaching">Teaching</a></li>
						<li><a href="#cv">CV & Bio</a></li>
						<li><a href="#slack">AI for Conservation Slack</a></li>
					</ul>
				</nav>
				<footer>
					<ul class="icons">
						<li><a href="mailto:beery@mit.edu" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
						<li><a href="https://scholar.google.com/citations?user=Hbr4c10AAAAJ&hl=en&oi=ao" class="icon solid fa-graduation-cap"><span class="label">Google Scholar</span></a></li>
						<li><a href="https://twitter.com/sarameghanbeery" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
						
					</ul>
				</footer>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- About -->
							<section id="about">
								<div class="image main" data-position="center">
									<img src="images/sara_field_work.jpeg" alt="" />
								</div>
								<div class="container">
									<header class="major">
										<h3>About</h3>
									</header>
																			
									<p>I'm an incoming assistant professor at <a href="https://www.eecs.mit.edu/research/artificial-intelligence-decision-making/">MIT EECS' Faculty of AI and Decision Making</a> and <a href="https://www.csail.mit.edu/">CSAIL</a>, and a Visiting Researcher at Google working on <a href="https://ai.googleblog.com/2022/06/mapping-urban-trees-across-north.html">Auto Arborist</a>.
										Iâ€™ve always loved the natural world, and I've seen 
										a growing need for technology-based approaches to conservation and 
										sustainability challenges.
										My research focuses on building computer vision methods that enable global-scale 
										environmental and biodiversity monitoring across data modalities, tackling real-world challenges including strong 
										spatiotemporal correlations that lead to domain shift, imperfect data quality, fine-grained categories, 
										and long-tailed distributions. I received my PhD in Computing and Mathematical Sciences (CMS) at 
										Caltech, advised by 
										<a href="http://www.vision.caltech.edu/Perona.html">Pietro Perona</a>, where I recieved the Amori Doctoral Prize for my dissertation. 
										I was honored to be awarded both the <a href="https://www.cms.caltech.edu/academics/honors#pimco">PIMCO Data Science Fellowship</a> 
										and the <a href="https://www.cms.caltech.edu/academics/honors#amazon">Amazon AI4Science Fellowship</a>, 
										which recognize senior graduate students that have had a remarkable impact in machine learning and data science,
										and in their application to fields beyond computer science. 
										My work has been funded in part by an 
										<a href="https://www.nsfgrfp.org/">NSF Graduate Research Fellowship</a> and the <a href="https://resnick.caltech.edu/">Caltech Resnick Sustainability Institute</a>. </p>
										
										
										<p>I seek to break down knowledge barriers between fields: I founded the successful 
										<a href="https://join.slack.com/t/aiforconservation/shared_invite/zt-9e1a80pf-Ez0UK51jYv1Lgd~Hwyy5Zw">AI for Conservation</a> 
										slack community (with over 1000 members) 
										and I am the founding director of the 
										<a href="https://cv4ecology.caltech.edu/">Caltech Summer School on Computer Vision Methods for Ecology</a>. 
									        I work closely with <a href="https://github.com/Microsoft/CameraTraps">Microsoft AI for Earth</a>, 
										<a href="https://ai.google/about/">Google Research</a>, 
										and <a href="https://wildlifeinsights.org/home-0">Wildlife Insights</a> 
										where I help turn my research into usable tools for the ecological community. </p>
										
									<p>I believe STEM should be accessible to all, regardless of gender, race, age, 
										nationality, sexuality, or religion. My experiences as a professional ballerina, 
										a nontraditional student, and a queer woman have taught me the value of unique and 
										diverse perspectives, both inside and outside of the research community. I am passionate 
										about increasing diversity and inclusion in STEM through mentorship, teaching, and outreach, 
										and was honored to have my DEI efforts recognized with the 
										inaugural <a href="https://www.cms.caltech.edu/about/diversity#gradient">Caltech Computing and Mathematical Sciences Department Gradient for Change Award</a> 
										and the inaugural <a href="http://kni.caltech.edu/news/eas-new-horizons-award-opportunity">Caltech Engineering and Applied Science Division New Horizons Award</a>.</p>
									</div>
							</section>
						
						<!-- Research Group -->
							<section id="research_group">
								<div class="container">
									<header class="major">
										<h3>Research Group</h3>
									</header>

									<p><b>I'm looking for postdoctoral researchers and PhD students to start with me at MIT in Fall 2023!</b><p>
									<p><b>Interested in a PhD?</b> I'll be considering students primarily via the MIT-WHOI joint program and MIT EECS, but I would be open to advising students with the right fit for my lab through MIT EAPS or MIT CEE if that is better aligned with your background. If you are interested in working with me on impact-driven computer vision research for the environment, biodiversity, conservation, and sustainability, apply to any of these programs in Fall 2022 and list me in your application.</p>
									<p><b>Interested in a postdoc?</b> Please email me directly at beery@mit.edu with [Postdoc starting 2023] in the title, and include a CV and short research statement, I'm particularly interested in hiring postdoctoral researchers with a strong background in quantitative ecology who would like to expand their research to include computer vision and machine learning approaches.</p> 	
  								</div>
							</section>
						
						<!-- Talks -->
						
						        <section id="talks">
								<div class="container">
									<h3>Selected Invited Talks</h3>
									
										<h4>Computer Vision for Global-Scale Biodiversity Monitoring - Scaling Geospatial and Taxonomic Coverage Using Contextual Clues</h4>
										<ul>
											<li>EPFL School of Computer & Communication Sciences Seminar, 2022</li>
											<li>ETH Zurich Sustainability Seminar, 2022</li>
											<li>MIT EECS Seminar, 2022</li>
											<li>Caltech Environmental Science and Engineering Seminar, 2022</li>
											<li>UC Berkeley EECS Seminar, 2022</li>
											<li>University of Washington Computer Science & Engineering Seminar, 2022</li>
											<li>Cornell University Computer Science Seminar, 2022</li>
											<li>UCSB PSTATS Seminar, 2022</li>
											<li>UCSB Computer Science & Computer Engineering Joint Seminar, 2022</li>
											<li>The Ohio State University Computer Science & Engineering Seminar, 2022</li>
											<li>University of Melbourne Computer Science Seminar, 2022</li>
											<li>Stevens Institute of Technology Data Science Seminar, 2022</li>
											<li>UCLA Electrical and Computer Engineering Seminar, 2022</li>
											<li>MIT Operations Research Center Seminar on Sustainability and Climate Change, 2022</li>
											<li>University of Sydney Computer Science Seminar, 2022</li>
											<li>Climate Change AI Seminar (with Dave Thau, Global Data and Technology Lead Scientist at WWF), 2022</li>
											<li>UCL Center for Biodiversity and Environment Research Seminar, 2022</li>
											<li>IST Austria Research Seminar, 2022</li>
											<li>Max Planck Institute for Intelligent Systems and Cyber Valley Scientific Symposium, 2022</li>
											<li>Georgia Tech Computational Science and Engineering Seminar, 2021</li>
											<li>University of New South Wales Cognitive Robotics Seminar, 2021</li>
											<li>Reed College Computer Science Seminar, 2021</li>
											<li>Berkeley AI + Climate Seminar, 2021</li>
											<li>University of Guelph CARE-AI and Biodiversity Institute Joint Seminar, 2021</li>
											<li>Seminar at Microsoft Research Cambridge, 2020</li>
											<li>Computational Sustainability (CompSust) Doctoral Consortium, 2020</li>
										</ul>
									        <h4>Edge AI for Wildlife Conservation</h4>
										<ul>
											<li>AJCAI Edge AI Workshop, 2022</li>
										</ul>
									        <h4>Joint Human-AI Elephant Population Monitoring - A Case Study in the Greater Mara Ecosystem</h4>
										<ul>
											<li>Keynote - The Second CV4Animals Workshop at CVPR, 2022</li>
										</ul>
										<h4>Beyond Benchmarks - Going from Competition-Winning Methods to Real-World Solutions</h4>
										<ul>
											<li>LifeCLEF, 2021</li>
											<li>Queer in AI at ICML, 2021</li>
										</ul>
										<h4>AI-Assisted Biodiversity Monitoring</h4>
										<ul>
											<li>Data Science Frontiers Seminar at the African Institute for Mathematical Sciences, 2021</li>
											<li>Leveraging AI to Extend Specimen Networks at iDigBio, 2021</li>
											<li>Princeton AI4All, 2021</li>
										</ul>
										<h4>Computer Vision for Biodiversity Monitoring and Conservation</h4>
										<ul>
											<li>EPFL Joint Mathis Lab Seminar, 2021</li>
											<li>AI for Mankind, 2021</li>
											<li>Yale Center for Biodiversity and Global Change Seminar, 2020</li>
										</ul>
										<h4>Deep Learning + Camera Traps</h4>
										<ul>
											<li>Plenary at Imaginecology Workshop (Deep Learning pour le traitement et lâ€™analyse dâ€™imageset de sons en Ã©cologie) at Le GDR EcoStat, 2020</li>
										</ul>
										<h4>Improving Computer Vision for Camera Traps: Leveraging Practitioner Insight to Build Solutions for Real-World Challenges</h4>
										<ul>
											<li>Ecological Society of America Annual Meeting, 2020</li>
											<li>CompSust Open Graduate Seminar, 2020</li>
											<li>Camera Trap Technology Symposium, 2019</li>
										</ul>
										<h4>AI for Camera Traps - Challenges, Best Practices, Benchmarks, and De-Siloing Data</h4>
										<ul>
											<li>World Agroforestry Centre (ICRAF) Seminar, 2020</li>
											<li>WILDLABS Virtual Meetup on Camera Trapping, 2019</li>
											<li>Computer Vision for Wildlife Conservation Workshop at ICCV, 2019</li>
										</ul>
										<h4>Computer Vision for Camera Traps</h4>
										<ul>
											<li>Caltech AI4Science Workshop, 2019</li>
											<li>USC Center for AI in Society Symposium on AI for Conservation, 2019</li>
											<li>Research Seminar at Google Venice, 2019</li>
										</ul>	
																			
	
  								</div>
							</section>

						<!-- Publications -->
							<section id="publications">
								<div class="container">
									<h3>Selected Publications</h3>
									<p><b>For a full list of publications please see my <a href="#cv" target="_self">CV</a> or <a href="https://scholar.google.com/citations?user=Hbr4c10AAAAJ&hl=en&oi=ao" target="_self">Google Scholar</a>.</b> </br>
									* denotes equal contribution </p>
									
									<div class="features">
										
										<article>
											<a href="https://arxiv.org/abs/2207.09295" class="image"><img src="images/fish_counting.png" alt="" /></a>
											<div class="inner">
												<p><b>The Caltech Fish Counting Dataset: A Benchmark for Multiple-Object Tracking and Counting.</b><br>
													Justin Kay, Peter Kulits, Suzanne Stathatos, Siqi Deng, Erik Young, <b>Sara Beery</b>, Grant Van Horn, and Pietro Perona.<br>
													ECCV 2022<br>
											           <a href="https://arxiv.org/abs/2207.09295" target="_self">[paper]</a>
													<a href="https://github.com/visipedia/caltech-fish-counting/" target="_self">[data]</a>
													
										                </p>
											</div>
										</article>

										<article>
											<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Beery_The_Auto_Arborist_Dataset_A_Large-Scale_Benchmark_for_Multiview_Urban_CVPR_2022_paper.html" class="image"><img src="images/Auto_Arborist_Overview%20(2).png" alt="" /></a>
											<div class="inner">
												<p><b>The Auto Arborist Dataset: A Large-Scale Benchmark for Multiview Urban Forest Monitoring Under Domain Shift</b><br>
													<b>Sara Beery</b>, Guanhang Wu, Trevor Edwards, Filip Pavetic, Bo Majewski, Shreyasee Mukherjee, Stanley Chan, John Morgan, Vivek Rathod, Jonathan Huang<br>
													CVPR 2022<br>
											           <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Beery_The_Auto_Arborist_Dataset_A_Large-Scale_Benchmark_for_Multiview_Urban_CVPR_2022_paper.html" target="_self">[paper]</a>
													<a href="https://google.github.io/auto-arborist/" target="_self">[data]</a>
													<a href="https://ai.googleblog.com/2022/06/mapping-urban-trees-across-north.html">[blog]</a>
										                </p>
											</div>
										</article>
										<article>
											<a href="https://www.nature.com/articles/s41467-022-27980-y" class="image"><img src="images/megadetector.png" alt="" /></a>
											<div class="inner">
												<p><b>Perspectives in Machine Learning for Wildlife Conservation</b><br>
												   Devis Tuia*, Benjamin Kellenberger*, <b>Sara Beery</b>*,  Blair R. Costelloe*, Silvia Zuffi, Benjamin Risse, Alexander Mathis, Mackenzie W. Mathis, Frank van Langevelde, Tilo Burghardt, Roland Kays, Holger Klinck, Martin Wikelski, Iain D. Couzin, Grant van Horn, Margaret C. Crofoot, Charles V. Stewart, Tanya Berger-Wolf<br>
											           Nature Communications 2022<br>
											           <a href="https://www.nature.com/articles/s41467-022-27980-y" target="_self">[paper]</a>
										                </p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/2112.05090" class="image"><img src="images/expanding.png" alt="" /></a>
											<div class="inner">
												<p><b>Extending the WILDS Benchmark for Unsupervised Adaptation</b><br>
												   Shiori Sagawa, Pang Wei Koh, Tony Lee, Irena Gao, Sang Michael Xie, Kendrick Shen, Ananya Kumar, Weihua Hu, Michihiro Yasunaga, Henrik Marklund, <b>Sara Beery</b>, Etienne David, Ian Stavness, Wei Guo, Jure Leskovec, Kate Saenko, Tatsunori Hashimoto, Sergey Levine, Chelsea Finn, Percy Liang<br>
											           ICLR 2022 (Oral)<br>
											           <a href="https://arxiv.org/abs/2112.05090" target="_self">[paper]</a><a href="https://github.com/p-lambda/wilds/releases/tag/v2.0.0" target="_self">[code/data]</a>
										                </p>
											</div>
										</article>
										<article>
											<a href="https://dl.acm.org/doi/fullHtml/10.1145/3466857" class="image"><img src="images/scaling_biodiversity.png" alt="" /></a>
											<div class="inner">
												<p><b>Scaling Biodiversity Monitoring for the Data Age</b><br>
												   <b>Sara Beery</b><br>
											           ACM XRDS 2021<br>
											           <a href="https://dl.acm.org/doi/pdf/10.1145/3466857" target="_self">[paper]</a>
										                </p>
											</div>
										</article>
										<article>
											<a href="http://proceedings.mlr.press/v139/koh21a/koh21a.pdf" class="image"><img src="images/wilds.png" alt="" /></a>
											<div class="inner">
												<p><b>Wilds: A benchmark of in-the-wild distribution shifts</b><br>
												Pang Wei Koh, Shiori Sagawa, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee, Etienne David, Ian Stavness, Wei Guo, Berton Earnshaw, Imran Haque, <b>Sara Beery</b>, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn, Percy Liang<br>
												ICLR 2021 (Oral)<br>
												<a href="http://proceedings.mlr.press/v139/koh21a/koh21a.pdf" target="_self">[paper]</a><a href="https://github.com/p-lambda/wilds" target="_self">[code/data]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/2103.16483" class="image"><img src="images/newt.png" alt="" /></a>
											<div class="inner">
												<p><b>Benchmarking Representation Learning for Natural World Image Collections</b><br>
												Grant Van Horn, Elijah Cole, <b>Sara Beery</b>, Kimberly Wilber, Serge Belongie, and Oisin Mac Aodha<br>
												CVPR 2021 (Oral)<br>
												<a href="https://arxiv.org/abs/2103.16483" target="_self">[paper]</a><a href="https://github.com/visipedia/newt" target="_self">[code/data]</a><a href="https://youtu.be/JuPUvgSnK6A" target="_self">[video]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/2103.16483" class="image"><img src="images/sdm.png" alt="" /></a>
											<div class="inner">
												<p><b>Species Distribution Modeling for Machine Learning Practitioners: A Review</b><br>
												<b>Sara Beery</b>*, Elijah Cole*, Joseph Parker, Pietro Perona, Kevin Winner<br>
												ACM COMPASS 2021<br>
												<a href="https://arxiv.org/abs/2107.10400" target="_self">[paper]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/2106.15083" class="image"><img src="images/elephantbook.png" alt="" /></a>
											<div class="inner">
												<p><b>ElephantBook: A Semi-Automated Human-in-the-Loop System for Elephant Re-Identification</b><br>
												Peter Kulits, Jake Wall, Anka Bedetti, Michelle Henley, <b>Sara Beery</b><br>
												ACM COMPASS 2021<br>
												<a href="https://arxiv.org/abs/2106.15083" target="_self">[paper]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/pdf/1910.09716" class="image"><img src="images/active.png" alt="" /></a>
											<div class="inner">
												<p><b>A Deep Active Learning System for Species Identification and Counting in Camera Trap Images</b><br>
												Mohammad Sadegh Norouzzadeh, Dan Morris, <b>Sara Beery</b>, Neel Joshi, Nebojsa Jojic, Jeff Clune<br>
												Methods in Ecology and Evolution 2021<br>
												<a href="https://arxiv.org/pdf/1910.09716" target="_self">[paper]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/pdf/1910.09716" class="image"><img src="images/trout.png" alt="" /></a>
											<div class="inner">
												<p><b>Automated Salmonid Counting in Sonar Data</b><br>
											        Peter Kulits, Angelina Pan, <b>Sara M Beery</b>, Erik Young, Pietro Perona, Grant Van Horn<br>
												Climate Change AI at NeurIPS 2020<br>
												<a href="https://www.climatechange.ai/papers/neurips2020/54.html" target="_self">[paper]</a><a href="https://slideslive.com/38942126" target="_self">[video]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/1912.03538" class="image"><img src="images/context-rcnn.png" alt="" /></a>
											<div class="inner">
												<p><b>Context R-CNN: Long Term Temporal Context for Per-Camera Object Detection</b><br>
												<b>Sara Beery</b>, Guanhang Wu, Vivek Rathod, Ronny Votel, Jonathan Huang<br>
												CVPR 2020<br>
												<a href="https://arxiv.org/abs/1912.03538" target="_self">[paper]</a><a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/context_rcnn.md" target="_self">[code]</a><a href="https://www.youtube.com/watch?v=fxLwzn6vyo4" target="_self">[video]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/1904.05916" class="image"><img src="images/synthetic.png" alt="" /></a>
											<div class="inner">
												<p><b>Synthetic Examples Improve Generalization for Rare Classes</b><br>
												<b>Sara Beery</b>, Yang Liu, Dan Morris, Jim Piavis, Ashish Kapoor, Markus Meister, Neel Joshi, Pietro Perona<br>
												WACV 2020<br>
												<a href="https://arxiv.org/abs/1904.05916" target="_self">[paper]</a></p>
											</div>
										</article>
										<article>
											<a href="https://dl.acm.org/doi/fullHtml/10.1145/3466857" class="image"><img src="images/cameratraps.png" alt="" /></a>
											<div class="inner">
												<p><b>Efficient Pipeline for Camera Trap Image Review</b><br>
												   <b>Sara Beery</b>, Dan Morris, Siyu Yang<br>
												   Data Mining and AI for Conservation at KDD 2018 <b>(Selected to be featured at KDD Earth Day)</b><br>
											           <a href="https://arxiv.org/abs/1907.06772" target="_self">[paper]</a><a href="https://github.com/microsoft/CameraTraps/blob/master/megadetector.md" target="_self">[code]</a>
										                </p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/1807.04975" class="image"><img src="images/terra_incognita.png" alt="" /></a>
											<div class="inner">
												<p><b>Recognition in Terra Incognita</b><br>
												<b>Sara Beery</b>, Grant Van Horn, Pietro Perona<br>
												ECCV 2018<br>
												<a href="https://arxiv.org/abs/1807.04975" target="_self">[paper]</a><a href="https://beerys.github.io/CaltechCameraTraps/" target="_self">[data]</a></p>
											</div>
										</article>
										<article>
											<a href="https://ieeexplore.ieee.org/document/7532575" class="image"><img src="images/motion.png" alt="" /></a>
											<div class="inner">
												<p><b>Finding Areas of Motion in Camera Trap Images</b><br>
												Agnieszka Miguel, <b>Sara Beery</b>, Erica Flores, Loren Klemesrud<br>
												IEEE ICIP 2016<br>
												<a href="https://ieeexplore.ieee.org/document/7532575" target="_self">[paper]</a></p>
											</div>
										</article>
										
									</div>
<!-- 									<h4>Workshop Publications</h4>
								        <div class="features">
										<article>
											<a href="https://arxiv.org/abs/2105.03494" class="image"><img src="images/iwildcam2021.jpeg" alt="" /></a>
											<div class="inner">
												<p><b>The iWildCam 2021 Competition Dataset</b><br>
												<b>Sara Beery</b>, Arushi Agarwal, Elijah Cole, Vighnesh Birodkar<br>
												FGVC8 at CVPR 2021<br>
												<a href="https://arxiv.org/abs/2105.03494" target="_self">[paper]</a><a href="https://github.com/visipedia/iwildcam_comp" target="_self">[data]</a><a href="https://www.kaggle.com/c/iwildcam2021-fgvc8" target="_self">[kaggle]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/2004.10340" class="image"><img src="images/iwildcam2021.jpeg" alt="" /></a>
											<div class="inner">
												<p><b>The iWildCam 2020 Competition Dataset</b><br>
												<b>Sara Beery</b>, Elijah Cole, Arvi Gjoka<br>
												FGVC7 at CVPR 2020<br>
												<a href="https://arxiv.org/abs/2004.10340" target="_self">[paper]</a><a href="https://github.com/visipedia/iwildcam_comp/tree/master/2020" target="_self">[data]</a><a href="https://www.kaggle.com/c/iwildcam-2020-fgvc7" target="_self">[kaggle]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/1907.07617" class="image"><img src="images/iwildcam2021.jpeg" alt="" /></a>
											<div class="inner">
												<p><b>The iWildCam 2019 Challenge Dataset</b><br>
												<b>Sara Beery</b>, Dan Morris, Pietro Perona<br>
												FGVC6 at CVPR 2019<br>
												<a href="https://arxiv.org/abs/1907.07617" target="_self">[paper]</a><a href="https://github.com/visipedia/iwildcam_comp/tree/master/2019" target="_self">[data]</a><a href="https://www.kaggle.com/c/iwildcam-2019-fgvc6" target="_self">[kaggle]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/1904.05986" class="image"><img src="images/iwildcam2021.jpeg" alt="" /></a>
											<div class="inner">
												<p><b>The iWildCam 2018 Challenge Dataset</b><br>
												<b>Sara Beery</b>, Grant van Horn, Oisin Mac Aodha, Pietro Perona<br>
												FGVC5 at CVPR 2018<br>
												<a href="https://arxiv.org/abs/1904.05986" target="_self">[paper]</a><a href="https://github.com/visipedia/iwildcam_comp/tree/master/2018" target="_self">[data]</a><a href="https://www.kaggle.com/c/iwildcam2018" target="_self">[kaggle]</a></p>
											</div>
										</article> -->
<!-- 								        </div> -->
								</div>
							</section>
		<!-- Talks -->
						
						        <section id="datasets">
								<div class="container">
									<h3>Datasets, Models, Competitions</h3>
									
									<h4><u><a href="https://wilds.stanford.edu/" target="_self">WILDS: Benchmark of In-The-Wild Distribution Shifts</a></u></h4>
									<h4><u><a href="https://github.com/visipedia/inat_comp/tree/master/2021" target="_self">iNaturalist 2021 Dataset</a></u></h4>
									        <ul>
											<li><a href="https://www.kaggle.com/c/inaturalist-2021" target="_self">iNaturalist 2021 Competition</a></li>
										</ul>
									<h4><u><a href="https://github.com/visipedia/newt" target="_self">NeWT 2021 Dataset</a></u></h4>
									<h4><u><a href="https://github.com/visipedia/iwildcam_comp" target="_self">iWildCam Datasets</a></u></h4>
									        <ul>
											<li><a href="https://www.kaggle.com/c/iwildcam2021-fgvc8" target="_self">iWildCam 2021 Competition</a></li>
											<li><a href="https://www.kaggle.com/c/iwildcam-2020-fgvc7" target="_self">iWildCam 2020 Competition</a></li>
											<li><a href="https://www.kaggle.com/c/iwildcam-2019-fgvc6" target="_self">iWildCam 2019 Competition</a></li>
											<li><a href="https://www.kaggle.com/c/iwildcam2018" target="_self">iWildCam 2018 Competition</a></li>
										</ul>	
									<h4><u><a href="https://beerys.github.io/CaltechCameraTraps/" target="_self">Caltech Camera Traps Dataset</a></u></h4>
									<h4><u><a href="https://github.com/microsoft/CameraTraps/blob/master/megadetector.md" target="_self">Microsoft AI for Earth MegaDetector Codebase and API</a></u></h4>
									<h4><u><a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/context_rcnn.md" target="_self">Context R-CNN Codebase (in the Tensorflow Object Detection API)</a></u></h4>
								
  								</div>
							</section>
						
						<!-- Teaching -->
						
						        <section id="teaching">
								<div class="container">
									<h3>Teaching</h3>
									<h4>Summer School in Computer Vision Methods for Ecology</h4>
																			
									<p>In Summer 2022 I will be directing the first annual Resnick Sustainability Institute Summer School on Computer Vision Methods for Ecology <a href="https://cv4ecology.caltech.edu/" target="_self">(https://cv4ecology.caltech.edu/)</a>. This intensive, three-week program will teach applied computer vision methods to senior ecology graduate students and postdocs.</p>
									<p>Students will develop hands-on computer vision systems to help answer their own ecological research questions, using their own data. They will receive daily mentorship from a passionate team of computer vision experts with a track record of impact in conservation and sustainability. Each student will be provided with $2500 in cloud credits to facilitate their project development sponsored by Microsoft AI for Earth and Amazon AWS. </p>
									<p>Our team of instructors will work with applicants leading up to the intensive to curate computer-vision-ready labels for their data that will be used to prototype systems for their research questions during the class. Students will leave the course empowered to build their own computer vision models for ecological applications, and gain skills in problem formulation, dataset curation, model training, model evaluation, and hosting models for inference. </p>
								        
									<h4>Co-Instructor, Caltech EE/CS/CNS 148b - Advanced Topics in Computer Vision, Spring 2021</h4>
									<p>I helped adapt this advanced projects-based computer vision course to focus on conservation and sustainability applications. To set up project groups for success, I curated a set of ecological challenges with publicly available image and video datasets and matched projects to NGOs and research groups that would directly benefit to provide domain expertise and context. I mentored 5 teams of computer vision students in structuring and defining these real-world challenges as computer vision and machine learning problems, and assisted them in holistically probing and evaluating their solutions and effectively communicating them to both computer vision and machine learning experts and the ecological community.</p>
  								
									<h4>Guest Lectures and Tutorials</h4>
									<ul>
										<li>Lecture at Caltech Ge/Bi/BE/CNS/ESE147: Quantitative Ecology, 2022</li>
										<li>Lecture at Caltech Bi 1: Principles of Biology, 2022</li>
										<li>Tutorial at 2D3DAI, 2021</li>
										<li>Lecture at Georgia Tech VIP-4601 VVS: HumaniTech, 2020</li>
										<li>Lecture at Georgia Tech VIP-4601 VWE: GaTech4Wildlife, 2020</li>
										<li>Tutorial at CompSust Doctoral Consortium, 2020</li>
										<li>Tutorial at WILDLABS Tech Tutors, 2020</li>
										<li>Lecture at Caltech EE/CNS/CS 148: Advanced Topics in Computer Vision, 2020</li>
									</ul>
								</div>
							</section>
						
						<!-- CV -->
						
						        <section id="cv">
								<div class="container">
									<h3>CV & Bio</h3>
									<p>Download my CV <a href="assets/Sara_Beery_Academic_CV.pdf" download="Sara_Beery_CV.pdf">here</a>. Last updated September 2022.</p>
									
									<p><b>Bio for invited talks</b></p>
									<p>Sara Beery will join MIT as an assistant professor in the Faculty of Artificial Intelligence and Decision-Making in EECS in September 2023. Beery received her PhD in computing and mathematical sciences at Caltech in 2022, where she was advised by Pietro Perona. Her research focuses on building computer vision methods that enable global-scale environmental and biodiversity monitoring across data modalities, tackling real-world challenges including strong spatiotemporal correlations, imperfect data quality, fine-grained categories, and long-tailed distributions. She partners with nongovernmental organizations and government agencies to deploy her methods in the wild worldwide and works toward increasing the diversity and accessibility of academic research in artificial intelligence through interdisciplinary capacity building and education.
									</p>


																			
										
  								</div>
							</section>
						
						<!-- AI for Conservation Slack -->
						
						        <section id="slack">
								<div class="container">
									<h3>AI for Conservation Slack</h3>
																			
									<p>In Fall of 2019 I started a Slack channel on AI for Conservation, to provide a shared, interdisciplinary space for researchers who work across the fields of computer vision, machine learning, and AI for conservation and sustainability applications to share opportunities, discuss best practices, and find collaborators. Now our community is over 1000 strong, with researchers from all over the globe. If you'd like to join us, just email <a href="mailto:aiforconservation@gmail.com" target="_self">(aiforconservation@gmail.com)</a></p>
										
  								</div>
								<div class="image main" data-position="center">
									<img src="images/sara_field_work_mep.jpg" alt="" />
								</div>
							</section>


						<!-- Five -->
						<!--
							<section id="five">
								<div class="container">
									<h3>Elements</h3>

									<section>
										<h4>Text</h4>
										<p>This is <b>bold</b> and this is <strong>strong</strong>. This is <i>italic</i> and this is <em>emphasized</em>.
										This is <sup>superscript</sup> text and this is <sub>subscript</sub> text.
										This is <u>underlined</u> and this is code: <code>for (;;) { ... }</code>. Finally, <a href="#">this is a link</a>.</p>
										<hr />
										<header>
											<h4>Heading with a Subtitle</h4>
											<p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
										</header>
										<p>Nunc lacinia ante nunc ac lobortis. Interdum adipiscing gravida odio porttitor sem non mi integer non faucibus ornare mi ut ante amet placerat aliquet. Volutpat eu sed ante lacinia sapien lorem accumsan varius montes viverra nibh in adipiscing blandit tempus accumsan.</p>
										<header>
											<h5>Heading with a Subtitle</h5>
											<p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
										</header>
										<p>Nunc lacinia ante nunc ac lobortis. Interdum adipiscing gravida odio porttitor sem non mi integer non faucibus ornare mi ut ante amet placerat aliquet. Volutpat eu sed ante lacinia sapien lorem accumsan varius montes viverra nibh in adipiscing blandit tempus accumsan.</p>
										<hr />
										<h2>Heading Level 2</h2>
										<h3>Heading Level 3</h3>
										<h4>Heading Level 4</h4>
										<h5>Heading Level 5</h5>
										<h6>Heading Level 6</h6>
										<hr />
										<h5>Blockquote</h5>
										<blockquote>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan faucibus. Vestibulum ante ipsum primis in faucibus lorem ipsum dolor sit amet nullam adipiscing eu felis.</blockquote>
										<h5>Preformatted</h5>
										<pre><code>i = 0;

while (!deck.isInOrder()) {
    print 'Iteration ' + i;
    deck.shuffle();
    i++;
}

print 'It took ' + i + ' iterations to sort the deck.';</code></pre>
									</section>

									<section>
										<h4>Lists</h4>
										<div class="row">
											<div class="col-6 col-12-xsmall">
												<h5>Unordered</h5>
												<ul>
													<li>Dolor pulvinar etiam magna etiam.</li>
													<li>Sagittis adipiscing lorem eleifend.</li>
													<li>Felis enim feugiat dolore viverra.</li>
												</ul>
												<h5>Alternate</h5>
												<ul class="alt">
													<li>Dolor pulvinar etiam magna etiam.</li>
													<li>Sagittis adipiscing lorem eleifend.</li>
													<li>Felis enim feugiat dolore viverra.</li>
												</ul>
											</div>
											<div class="col-6 col-12-xsmall">
												<h5>Ordered</h5>
												<ol>
													<li>Dolor pulvinar etiam magna etiam.</li>
													<li>Etiam vel felis at lorem sed viverra.</li>
													<li>Felis enim feugiat dolore viverra.</li>
													<li>Dolor pulvinar etiam magna etiam.</li>
													<li>Etiam vel felis at lorem sed viverra.</li>
													<li>Felis enim feugiat dolore viverra.</li>
												</ol>
												<h5>Icons</h5>
												<ul class="icons">
													<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
													<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
													<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
													<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
													<li><a href="#" class="icon brands fa-dribbble"><span class="label">Dribbble</span></a></li>
													<li><a href="#" class="icon brands fa-tumblr"><span class="label">Tumblr</span></a></li>
												</ul>
											</div>
										</div>
										<h5>Actions</h5>
										<ul class="actions">
											<li><a href="#" class="button primary">Default</a></li>
											<li><a href="#" class="button">Default</a></li>
											<li><a href="#" class="button alt">Default</a></li>
										</ul>
										<ul class="actions small">
											<li><a href="#" class="button primary small">Small</a></li>
											<li><a href="#" class="button small">Small</a></li>
											<li><a href="#" class="button alt small">Small</a></li>
										</ul>
										<div class="row">
											<div class="col-3 col-6-medium col-12-xsmall">
												<ul class="actions stacked">
													<li><a href="#" class="button primary">Default</a></li>
													<li><a href="#" class="button">Default</a></li>
													<li><a href="#" class="button alt">Default</a></li>
												</ul>
											</div>
											<div class="col-3 col-6 col-12-xsmall">
												<ul class="actions stacked">
													<li><a href="#" class="button primary small">Small</a></li>
													<li><a href="#" class="button small">Small</a></li>
													<li><a href="#" class="button alt small">Small</a></li>
												</ul>
											</div>
											<div class="col-3 col-6-medium col-12-xsmall">
												<ul class="actions stacked">
													<li><a href="#" class="button primary fit">Default</a></li>
													<li><a href="#" class="button fit">Default</a></li>
													<li><a href="#" class="button alt fit">Default</a></li>
												</ul>
											</div>
											<div class="col-3 col-6-medium col-12-xsmall">
												<ul class="actions stacked">
													<li><a href="#" class="button primary small fit">Small</a></li>
													<li><a href="#" class="button small fit">Small</a></li>
													<li><a href="#" class="button alt small fit">Small</a></li>
												</ul>
											</div>
										</div>
									</section>

									<section>
										<h4>Table</h4>
										<h5>Default</h5>
										<div class="table-wrapper">
											<table>
												<thead>
													<tr>
														<th>Name</th>
														<th>Description</th>
														<th>Price</th>
													</tr>
												</thead>
												<tbody>
													<tr>
														<td>Item One</td>
														<td>Ante turpis integer aliquet porttitor.</td>
														<td>29.99</td>
													</tr>
													<tr>
														<td>Item Two</td>
														<td>Vis ac commodo adipiscing arcu aliquet.</td>
														<td>19.99</td>
													</tr>
													<tr>
														<td>Item Three</td>
														<td> Morbi faucibus arcu accumsan lorem.</td>
														<td>29.99</td>
													</tr>
													<tr>
														<td>Item Four</td>
														<td>Vitae integer tempus condimentum.</td>
														<td>19.99</td>
													</tr>
													<tr>
														<td>Item Five</td>
														<td>Ante turpis integer aliquet porttitor.</td>
														<td>29.99</td>
													</tr>
												</tbody>
												<tfoot>
													<tr>
														<td colspan="2"></td>
														<td>100.00</td>
													</tr>
												</tfoot>
											</table>
										</div>

										<h5>Alternate</h5>
										<div class="table-wrapper">
											<table class="alt">
												<thead>
													<tr>
														<th>Name</th>
														<th>Description</th>
														<th>Price</th>
													</tr>
												</thead>
												<tbody>
													<tr>
														<td>Item One</td>
														<td>Ante turpis integer aliquet porttitor.</td>
														<td>29.99</td>
													</tr>
													<tr>
														<td>Item Two</td>
														<td>Vis ac commodo adipiscing arcu aliquet.</td>
														<td>19.99</td>
													</tr>
													<tr>
														<td>Item Three</td>
														<td> Morbi faucibus arcu accumsan lorem.</td>
														<td>29.99</td>
													</tr>
													<tr>
														<td>Item Four</td>
														<td>Vitae integer tempus condimentum.</td>
														<td>19.99</td>
													</tr>
													<tr>
														<td>Item Five</td>
														<td>Ante turpis integer aliquet porttitor.</td>
														<td>29.99</td>
													</tr>
												</tbody>
												<tfoot>
													<tr>
														<td colspan="2"></td>
														<td>100.00</td>
													</tr>
												</tfoot>
											</table>
										</div>
									</section>

									<section>
										<h4>Buttons</h4>
										<ul class="actions">
											<li><a href="#" class="button primary">Primary</a></li>
											<li><a href="#" class="button">Default</a></li>
											<li><a href="#" class="button alt">Alternate</a></li>
										</ul>
										<ul class="actions">
											<li><a href="#" class="button primary large">Large</a></li>
											<li><a href="#" class="button">Default</a></li>
											<li><a href="#" class="button alt small">Small</a></li>
										</ul>
										<ul class="actions fit">
											<li><a href="#" class="button primary fit">Fit</a></li>
											<li><a href="#" class="button fit">Fit</a></li>
											<li><a href="#" class="button alt fit">Fit</a></li>
										</ul>
										<ul class="actions fit small">
											<li><a href="#" class="button primary fit small">Fit + Small</a></li>
											<li><a href="#" class="button fit small">Fit + Small</a></li>
											<li><a href="#" class="button alt fit small">Fit + Small</a></li>
										</ul>
										<ul class="actions">
											<li><a href="#" class="button primary icon solid fa-download">Icon</a></li>
											<li><a href="#" class="button icon solid fa-download">Icon</a></li>
											<li><a href="#" class="button alt icon solid fa-check">Icon</a></li>
										</ul>
										<ul class="actions">
											<li><span class="button primary disabled">Primary</span></li>
											<li><span class="button disabled">Default</span></li>
											<li><span class="button alt disabled">Alternate</span></li>
										</ul>
									</section>

									<section>
										<h4>Form</h4>
										<form method="post" action="#">
											<div class="row gtr-uniform">
												<div class="col-6 col-12-xsmall">
													<input type="text" name="demo-name" id="demo-name" value="" placeholder="Name" />
												</div>
												<div class="col-6 col-12-xsmall">
													<input type="email" name="demo-email" id="demo-email" value="" placeholder="Email" />
												</div>
												<div class="col-12">
													<select name="demo-category" id="demo-category">
														<option value="">- Category -</option>
														<option value="1">Manufacturing</option>
														<option value="1">Shipping</option>
														<option value="1">Administration</option>
														<option value="1">Human Resources</option>
													</select>
												</div>
												<div class="col-4 col-12-medium">
													<input type="radio" id="demo-priority-low" name="demo-priority" checked>
													<label for="demo-priority-low">Low Priority</label>
												</div>
												<div class="col-4 col-12-medium">
													<input type="radio" id="demo-priority-normal" name="demo-priority">
													<label for="demo-priority-normal">Normal Priority</label>
												</div>
												<div class="col-4 col-12-medium">
													<input type="radio" id="demo-priority-high" name="demo-priority">
													<label for="demo-priority-high">High Priority</label>
												</div>
												<div class="col-6 col-12-medium">
													<input type="checkbox" id="demo-copy" name="demo-copy">
													<label for="demo-copy">Email me a copy of this message</label>
												</div>
												<div class="col-6 col-12-medium">
													<input type="checkbox" id="demo-human" name="demo-human" checked>
													<label for="demo-human">I am a human and not a robot</label>
												</div>
												<div class="col-12">
													<textarea name="demo-message" id="demo-message" placeholder="Enter your message" rows="6"></textarea>
												</div>
												<div class="col-12">
													<ul class="actions">
														<li><input type="submit" value="Send Message" /></li>
														<li><input type="reset" value="Reset" class="alt" /></li>
													</ul>
												</div>
											</div>
										</form>
									</section>

									<section>
										<h4>Image</h4>
										<h5>Fit</h5>
										<span class="image fit"><img src="images/banner.jpg" alt="" /></span>
										<div class="box alt">
											<div class="row gtr-50 gtr-uniform">
												<div class="col-4"><span class="image fit"><img src="images/pic01.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic02.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic03.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic02.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic03.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic01.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic03.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic01.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic02.jpg" alt="" /></span></div>
											</div>
										</div>
										<h5>Left &amp; Right</h5>
										<p><span class="image left"><img src="images/avatar.jpg" alt="" /></span>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.</p>
										<p><span class="image right"><img src="images/avatar.jpg" alt="" /></span>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.</p>
									</section>

								</div>
							</section>
						-->

					</div>

				<!-- Footer -->
					<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>&copy; Sara Beery. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
